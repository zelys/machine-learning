{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7/F5/cs2fmav8nWq5a7Xh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Para saber más: estimación de la regresión lineal simple**"],"metadata":{"id":"DJQMgpnB2MqJ"}},{"cell_type":"markdown","source":["La regresión lineal fue la metodología que ajustó la mejor línea que representa linealmente la interacción entre X e Y; en nuestro caso, el tamaño del área del primer piso y el precio de venta de la casa.\n","\n","Vale la pena repasar cada componente de la regresión lineal:"],"metadata":{"id":"bw3JIf3i2PlO"}},{"cell_type":"markdown","source":["## **Función**"],"metadata":{"id":"Vto4dezf2TiP"}},{"cell_type":"markdown","source":["![imagen](http://cdn3.gnarususercontent.com.br/2145-data-science-probando-relaciones-con-regresion-lineal/Imagenes/5.IMG1-ParaSaberMasEquacion.png)"],"metadata":{"id":"Z-pXGC1w2WdK"}},{"cell_type":"markdown","source":["- **Variable Respuesta (Y):** También llamada variable dependiente, es aquella que estamos tratando de predecir.\n","- **Intercepto (β₀):** El punto donde la línea de regresión intercepta el eje vertical (Y), es decir, el valor de Y cuando X es igual a 0.\n","- **Variable Explicativa (X):** También llamada variable independiente, es el factor que usamos para predecir y explicar la variable respuesta.\n","- **Coeficientes de Regresión (β₁):** Impacto de cada variable explicativa X en la variable respuesta, es el efecto de X en Y.\n","- E**rror Residual (e):** Diferencia entre los valores reales y previstos de la variable respuesta."],"metadata":{"id":"WqTxr8vA2c14"}},{"cell_type":"markdown","source":["## **Coeficientes**"],"metadata":{"id":"cRlRIM0f2pfe"}},{"cell_type":"markdown","source":["La relación lineal entre las variables X e Y se representa gráficamente por una línea. Este proceso de encontrar la línea ideal implica minimizar la distancia entre los puntos reales y la propia línea.\n","\n","El ajuste de la línea de regresión lineal se simplifica mediante el método de los mínimos cuadrados. Este método tiene como objetivo encontrar la línea que mejor se ajusta a los datos observados, minimizando la suma de los cuadrados de las diferencias entre los valores reales y los valores previstos por la línea y calculando los coeficientes del modelo."],"metadata":{"id":"dovjxmUj2sy-"}},{"cell_type":"markdown","source":["![imagen1](http://cdn3.gnarususercontent.com.br/2145-data-science-probando-relaciones-con-regresion-lineal/Imagenes/5.IMG2-ParaSaberMasGrafico.png)"],"metadata":{"id":"9TW8mJmB2uWb"}},{"cell_type":"markdown","source":["# **Para saber más: explicabilidad**"],"metadata":{"id":"yaRFB8xe2yzw"}},{"cell_type":"markdown","source":["El coeficiente de determinación, frecuentemente llamado R², es una medida estadística que indica cuánto de la variabilidad de la variable dependiente (respuesta) es explicada por el modelo de regresión lineal."],"metadata":{"id":"3_7liZcp3mvM"}},{"cell_type":"markdown","source":["## **Interpretando el R**²"],"metadata":{"id":"gmtVYtOs3oJg"}},{"cell_type":"markdown","source":["Varía de 0 a 1, un valor cercano a 1 indica que el modelo se ajusta bien a los datos, explicando la mayor parte de la variación en la variable dependiente/respuesta. Por otro lado, un valor cercano a 0 indica que el modelo no puede explicar mucha variación en la variable dependiente/respuesta."],"metadata":{"id":"CsFw6oyB3qSU"}},{"cell_type":"markdown","source":["## **Usando en la prueba**"],"metadata":{"id":"6M6l5ubg3rwm"}},{"cell_type":"markdown","source":["Además, el R² puede ser utilizado para comparar el rendimiento del modelo en diferentes conjuntos de datos, como entrenamiento y prueba. Esto ayuda a identificar problemas de sobreajuste (overfitting) o subajuste (underfitting). Idealmente, deseamos que el R² sea consistente entre los conjuntos de entrenamiento y prueba, indicando una buena capacidad de generalización del modelo para nuevos datos."],"metadata":{"id":"zuUtfp5Y3uBN"}},{"cell_type":"markdown","source":["## **Fórmula**"],"metadata":{"id":"O44bEv783vbS"}},{"cell_type":"markdown","source":["Una de las fórmulas del R² puede ser representada por la razón entre la variación explicada y la variación total. Por eso decimos que cuanto más cerca de 1, mejor es la adecuación del modelo, ya que la variación explicada será más cercana a la variación total en esta razón."],"metadata":{"id":"Z1qhvwJp3yDj"}},{"cell_type":"markdown","source":["![imagen2](http://cdn3.gnarususercontent.com.br/2145-data-science-probando-relaciones-con-regresion-lineal/Imagenes/7.ParaSaberMas.png)"],"metadata":{"id":"QGrdtFzy3zct"}},{"cell_type":"markdown","source":["# **Importancia de las variables**"],"metadata":{"id":"UdYGsTnL33gQ"}},{"cell_type":"markdown","source":["Imagina que eres un(a) analista de datos trabajando en el Banco Bytebank. Este banco desea ofrecer a sus clientes préstamos con tasas de interés más precisas, basadas en un análisis detallado del valor de las propiedades. Para ello, debes desarrollar un modelo de regresión lineal que pueda predecir el precio de venta de casas en función de diversas características.\n","\n","Inicialmente, ajustaste un modelo, utilizando solo el tamaño del primer piso como variable. Sin embargo, para mejorar tu modelo, decides explorar otros factores que pueden influir en el precio de venta, utilizando la herramienta pairplot para visualizar las relaciones entre estas variables y el precio.\n","\n","**¿Cuál de las siguientes afirmaciones describe mejor la importancia de incluir múltiples variables explicativas en el modelo de regresión lineal?**"],"metadata":{"id":"WKEdULMy_SSo"}},{"cell_type":"markdown","source":["**RESPUESTA:**"],"metadata":{"id":"LobjfXkz_UQ1"}},{"cell_type":"markdown","source":["Al agregar más variables explicativas relacionadas con el precio de venta de las casas, el modelo se vuelve menos propenso a sesgos, ya que considera una gama más amplia de características que afectan el valor de la propiedad, proporcionando estimaciones más precisas."],"metadata":{"id":"foLIwPAB_W1A"}},{"cell_type":"markdown","source":["> *La inclusión de más variables explicativas puede ayudar a reducir el sesgo y mejorar la precisión del modelo, considerando una variedad más amplia de factores que influyen en el precio de una propiedad.*"],"metadata":{"id":"1UJw3eR1_b2-"}},{"cell_type":"markdown","source":["# **El papel del R² en la selección del modelo**"],"metadata":{"id":"2MvsTzTN_fE9"}},{"cell_type":"markdown","source":["En un proyecto de análisis de datos, un científico de datos compara cuatro modelos estadísticos para predecir el precio de las casas. Cada modelo utiliza un conjunto diferente de variables explicativas. El científico observa que los modelos con más variables tienen valores de R² más altos, pero es consciente de que esto puede no ser el único factor para elegir el mejor modelo. Con base en esta situación, **¿cuál de las siguientes afirmaciones es la más adecuada para seleccionar el modelo más apropiado?**"],"metadata":{"id":"EgHY2hB1CQLj"}},{"cell_type":"markdown","source":["**Respuesta:**"],"metadata":{"id":"dUmHcAVdCYm6"}},{"cell_type":"markdown","source":["Prefiera el modelo con el R² ajustado más alto, ya que este tiene en cuenta el número de variables explicativas, ayudando a evitar el sobreajuste."],"metadata":{"id":"rLmq7A_jCdfo"}},{"cell_type":"markdown","source":["> *El R² ajustado es una medida más robusta que el R² simple, ya que penaliza la inclusión de variables que no contribuyen significativamente al modelo. Esto ayuda a equilibrar la complejidad del modelo con su capacidad explicativa, proporcionando una base más sólida para la elección del modelo.*"],"metadata":{"id":"1zjBcFoXCeRT"}},{"cell_type":"markdown","source":["# **Para saber más: refinando la selección de modelos**"],"metadata":{"id":"GJm-mRAfChg6"}},{"cell_type":"markdown","source":["En la clase sobre comparación de modelos de regresión lineal, exploramos cómo evaluar y seleccionar el modelo más adecuado utilizando el R² y otros criterios. Además de la selección manual que discutimos, existen métodos automáticos de selección de variables que pueden ser extremadamente útiles en situaciones donde el número de variables explicativas es grande. Estos métodos, como stepwise, backward y forward selection, siguen criterios predefinidos para agregar o eliminar variables del modelo de forma iterativa. Explora a continuación los métodos automáticos de selección de variables, que buscan equilibrar la complejidad del modelo y su capacidad explicativa."],"metadata":{"id":"R2NK8ZmsClSY"}},{"cell_type":"markdown","source":["- El método de forward selection comienza con un modelo sin variables explicativas y agrega una a una, eligiendo en cada paso la variable que más mejora el modelo de acuerdo con un criterio estadístico específico, como el menor valor de p-valor o el mayor aumento en el R² ajustado.\n","- El backward selection inicia con todas las variables posibles en el modelo y, de manera iterativa, elimina la variable que menos contribuye al modelo, nuevamente basándose en criterios como el p-valor o el impacto en el R² ajustado.\n","- El stepwise selection es una combinación de los dos métodos anteriores, donde las variables pueden ser agregadas o eliminadas en cada paso, dependiendo de su contribución a la mejora del modelo."],"metadata":{"id":"8Mdj9ulECnSY"}},{"cell_type":"markdown","source":["Estos métodos de selección automática son herramientas poderosas que ayudan en la identificación del modelo más parsimonioso, es decir, aquel que puede explicar los datos de manera eficiente sin ser excesivamente complejo. Sin embargo, es crucial que el científico de datos comprenda y supervise el proceso, ya que la elección automática puede, a veces, introducir sesgo o sobreajuste, especialmente si el criterio de selección no es bien elegido o si el modelo no es validado adecuadamente con datos nuevos o de prueba."],"metadata":{"id":"8gpdj-qXCq-U"}},{"cell_type":"markdown","source":["# **Comparación entre R² de entrenamiento y prueba**"],"metadata":{"id":"ZIsz5eKZGtTH"}},{"cell_type":"markdown","source":["El coeficiente de determinación (R²) es una métrica fundamental en modelos de regresión, ya que indica la proporción de la varianza en la variable de respuesta que es explicada por las variables explicativas. Considerando este contexto, ¿por qué es importante comparar el R² calculado con los datos de entrenamiento y también con los datos de prueba en modelos de regresión? Elige la alternativa correcta."],"metadata":{"id":"FzXHTdvBGu-s"}},{"cell_type":"markdown","source":["**Respuesta:**"],"metadata":{"id":"HocZFREbGws4"}},{"cell_type":"markdown","source":["Para determinar si el modelo está sobreajustado a los datos de entrenamiento (overfitting), perdiendo la capacidad de generalización."],"metadata":{"id":"K4Nn7NSZGzsr"}},{"cell_type":"markdown","source":["> Comparar el R² de entrenamiento y prueba ayuda a identificar si el modelo está sobreajustado a los datos de entrenamiento (overfitting), lo que perjudica su capacidad de generalización. Si hay una diferencia muy grande entre los valores de entrenamiento y prueba, puede indicar que el modelo está siendo influenciado por patrones específicos de los datos de entrenamiento que no son generalizables a los datos de prueba."],"metadata":{"id":"50WW-nF-G3Bi"}},{"cell_type":"markdown","source":["# **Para saber más: guardando el modelo en un archivo**"],"metadata":{"id":"LyCAHZDDKGB-"}},{"cell_type":"markdown","source":["Al desarrollar modelos de regresión con Statsmodels, es común querer guardar estos modelos para uso futuro, ya sea para implementación en producción, compartir con otros miembros del equipo o simplemente para respaldo. Una manera conveniente de hacer esto en Python es usando la biblioteca `pickle`, que permite serializar objetos de Python en archivos y deserializarlos de vuelta a objetos de Python. Esta biblioteca no necesita ser instalada, ya que viene por defecto en Python."],"metadata":{"id":"OQqFyYedKKq2"}},{"cell_type":"markdown","source":["Vamos a explorar cómo guardar un modelo de regresión lineal de Statsmodels con la biblioteca `pickle` y luego cómo leer el archivo."],"metadata":{"id":"Yr5lPuArKOk1"}},{"cell_type":"markdown","source":["## **Cómo guardar el Modelo con Pickle**"],"metadata":{"id":"bIdykgijKQNk"}},{"cell_type":"markdown","source":["Después de entrenar el modelo, podemos guardarlo en un archivo usando la biblioteca pickle. Para ello, es necesario importar la biblioteca y luego podemos usar la función `pickle.dump()`, indicando el modelo y el archivo como parámetros."],"metadata":{"id":"8PYc1x2xKSX1"}},{"cell_type":"markdown","source":["\n","\n","```\n","import pickle\n","\n","# Nombre del archivo donde se guardará el modelo\n","nombre_archivo = 'modelo_regresion_lineal.pkl'\n","\n","# Guardar el modelo en un archivo usando pickle\n","with open(nombre_archivo, 'wb') as archivo:\n","    pickle.dump(modelo, archivo)\n","```\n","\n"],"metadata":{"id":"mIJgdiyvMDsy"}},{"cell_type":"markdown","source":["## **Cargar el Modelo de vuelta con Pickle**"],"metadata":{"id":"l2I3ezfkKYqq"}},{"cell_type":"markdown","source":["Después de guardar el modelo, podemos cargarlo de vuelta para uso posterior. Para hacer esto, simplemente usamos el método [pickle.load()](https://docs.python.org/3/library/pickle.html#pickle.load) utilizando el archivo como parámetro de la función."],"metadata":{"id":"GMO4yy5vKeMV"}},{"cell_type":"markdown","source":["\n","\n","```\n","# Cargar el modelo de vuelta del archivo\n","with open(nombre_archivo, 'rb') as archivo:\n","    modelo_cargado = pickle.load(archivo)\n","```\n","\n"],"metadata":{"id":"EYRmn8V_MHGt"}},{"cell_type":"markdown","source":["A partir de la lectura del archivo, es posible utilizar el modelo para hacer predicciones y verificar métricas de la misma manera que usamos el modelo original.\n","\n","Para más detalles sobre el uso de la biblioteca pickle, consulte la [documentación](https://docs.python.org/3/library/pickle.html)."],"metadata":{"id":"dtvQxwh5Knut"}},{"cell_type":"markdown","source":["# **Estrategia para la optimización de modelos de regresión**"],"metadata":{"id":"ui0c0xW4Ks4W"}},{"cell_type":"markdown","source":["Ana está analizando la multicolinealidad en su modelo de regresión lineal, que fue construido para predecir los precios de inmuebles en función de varias características. Ella notó que dos variables, \"existe_segundo_andar\" y \"area_segundo_andar\", tienen VIFs de 7.455059 y 7.589396, respectivamente. ¿Cuál de las siguientes afirmaciones describe mejor la situación y los pasos que Ana puede tomar para abordar el problema de multicolinealidad?"],"metadata":{"id":"Oz0XVQz0M0m9"}},{"cell_type":"markdown","source":["**Respuestas:**"],"metadata":{"id":"Vhe498DmM2-i"}},{"cell_type":"markdown","source":["1. Los VIFs muestran una fuerte evidencia de multicolinealidad. Ana puede considerar combinar ambas en una sola variable."],"metadata":{"id":"1AuR8ChTM65-"}},{"cell_type":"markdown","source":["> *Combinar ambas características en una sola variable es una posibilidad viable para resolver el problema de la multicolinealidad, pero también tiene desventajas. La principal es la pérdida de interpretabilidad. Al combinar variables, puedes perder la capacidad de entender cómo cada variable original contribuye individualmente a explicar la variable dependiente. Además, no hay garantía de que la combinación de variables resolverá completamente el problema de la multicolinealidad, especialmente si hay múltiples variables altamente correlacionadas que contribuyen a la complejidad del modelo...*"],"metadata":{"id":"bSXZ43wHNBLf"}},{"cell_type":"markdown","source":["2. Los VIFs muestran una fuerte evidencia de multicolinealidad. Ana puede considerar eliminar una de las variables para reducir la multicolinealidad."],"metadata":{"id":"5YNfftSmNGl4"}},{"cell_type":"markdown","source":["> *Los valores de VIF superiores a 5 generalmente indican una fuerte multicolinealidad, sugiriendo que las variables están correlacionadas y pueden influir negativamente en la interpretación de los coeficientes del modelo. Al eliminar o combinar variables correlacionadas, Ana puede mejorar la precisión y la interpretabilidad de su modelo de regresión lineal.*"],"metadata":{"id":"URa_TFXrNKpY"}},{"cell_type":"markdown","source":["# **Para saber más: entendiendo la heterocedasticidad**"],"metadata":{"id":"wDKFpw1HNN0A"}},{"cell_type":"markdown","source":["Cuando nos sumergimos en el universo del análisis de datos, un concepto fundamental que encontramos con frecuencia es la regresión lineal. Esta técnica nos permite entender relaciones y prever tendencias basándonos en datos existentes. Sin embargo, al aplicar la regresión lineal, es crucial estar atentos a la heterocedasticidad, una característica que puede afectar significativamente la interpretación de los resultados."],"metadata":{"id":"ypwp5AxiQ6D1"}},{"cell_type":"markdown","source":["## **¿Qué es la Heterocedasticidad?**"],"metadata":{"id":"qGawb_y5Q71S"}},{"cell_type":"markdown","source":["La heterocedasticidad es un término utilizado en estadística para describir una situación en la que la varianza de los errores (o residuos) de un modelo de regresión no es constante a lo largo del rango de valores previstos. En términos simples, si la dispersión de los residuos varía en diferentes niveles del predictor, estamos ante la heterocedasticidad. Esto es un problema porque la mayoría de los métodos de regresión lineal asumen homocedasticidad, es decir, que los residuos tienen varianza constante en todos los niveles de los predictores."],"metadata":{"id":"EPZ0x3jVQ_uT"}},{"cell_type":"markdown","source":["![img1](http://cdn3.gnarususercontent.com.br/2145-data-science-probando-relaciones-con-regresion-lineal/Imagenes/6.ParaSaberMas.png)"],"metadata":{"id":"lbHPSFmxRBW9"}},{"cell_type":"markdown","source":["## **¿Por qué es un Problema la Heterocedasticidad?**"],"metadata":{"id":"jiYQnPQ9RG0f"}},{"cell_type":"markdown","source":["La presencia de heterocedasticidad puede llevar a estimaciones de coeficientes ineficientes y a pruebas de hipótesis inválidas, comprometiendo la confiabilidad de las inferencias estadísticas. Aunque no afecta la imparcialidad o la consistencia de los estimadores de mínimos cuadrados ordinarios, impacta en la eficiencia de estos estimadores, haciéndolos menos confiables."],"metadata":{"id":"LN8T6LCCRKDX"}},{"cell_type":"markdown","source":["## **Identificando la Heterocedasticidad**"],"metadata":{"id":"v1APTlzyRL86"}},{"cell_type":"markdown","source":["Uno de los métodos más comunes para detectar la heterocedasticidad es a través del análisis visual de los residuos. Después de ajustar un modelo de regresión lineal, podemos graficar los residuos en función de los valores previstos. Si los residuos se dispersan de manera uniforme, sin formar patrones o embudos, el modelo probablemente presenta homocedasticidad. Por otro lado, si la dispersión de los residuos aumenta o disminuye con los valores previstos, esto indica heterocedasticidad."],"metadata":{"id":"R6Trl0Y_RO17"}},{"cell_type":"markdown","source":["## **¿Cómo Evaluar la Heterocedasticidad?**"],"metadata":{"id":"fnGyS_alRQJw"}},{"cell_type":"markdown","source":["Además de un análisis visual de los residuos, existen varias pruebas estadísticas para evaluar formalmente la presencia de heterocedasticidad, como la prueba de White y la prueba de Breusch-Pagan. Estas pruebas ayudan a cuantificar si la varianza de los residuos está relacionada con los valores previstos, proporcionando una base más sólida para decidir si la heterocedasticidad es una preocupación significativa en el modelo."],"metadata":{"id":"Mow-GWl_RTe_"}},{"cell_type":"markdown","source":["## **Tratando la Heterocedasticidad**"],"metadata":{"id":"UVtCjprXRU9H"}},{"cell_type":"markdown","source":["Si identificamos heterocedasticidad, se pueden adoptar varias enfoques para abordar el problema, como la transformación de variables (por ejemplo, logarítmica o raíz cuadrada) o el uso de técnicas de regresión robustas, que son menos sensibles a la varianza de los residuos."],"metadata":{"id":"pvxdjmrRRYfh"}},{"cell_type":"markdown","source":["## **Conclusión**"],"metadata":{"id":"pQF2R2rtRaSy"}},{"cell_type":"markdown","source":["Al comprender e identificar la heterocedasticidad, podemos tomar medidas apropiadas para garantizar que nuestros análisis de regresión lineal sean confiables y válidos. Este cuidado nos permite hacer inferencias más precisas y fundamentadas, esenciales para la toma de decisiones basadas en datos."],"metadata":{"id":"7VRy43ZXRdGK"}},{"cell_type":"markdown","source":["# **Evaluando la dispersión de los residuos**"],"metadata":{"id":"n5NygqfGRepE"}},{"cell_type":"markdown","source":["João está analizando la eficacia de un modelo de regresión utilizado para fijar precios de casas. Examinó un gráfico de dispersión de los residuos (diferencia entre los valores reales y estimados) en relación con los precios previstos de las casas. João se dio cuenta de que, aunque la mayoría de los residuos están alrededor de 0, la dispersión de los residuos aumenta a medida que el precio previsto de las casas aumenta. Ante este escenario, ¿qué indica esta observación sobre el modelo? Elige la alternativa correcta."],"metadata":{"id":"ViIcJq-ARh5L"}},{"cell_type":"markdown","source":["**Respuesta:**"],"metadata":{"id":"VxHBcuzCRj5q"}},{"cell_type":"markdown","source":["A medida que el precio de las casas aumenta, el modelo se vuelve menos confiable, indicado por la mayor dispersión de los residuos."],"metadata":{"id":"0K1F7ScHRl6v"}},{"cell_type":"markdown","source":["> *Una dispersión creciente de los residuos en relación con el aumento del precio previsto indica que el modelo tiene dificultades para predecir con precisión casas de mayor valor. Esto sugiere que el modelo puede no estar capturando todas las variables o patrones relevantes para casas más caras, resultando en predicciones menos precisas para esos inmuebles.*"],"metadata":{"id":"TFxFSjkaRo7V"}},{"cell_type":"markdown","source":["# **Para ir más profundo**"],"metadata":{"id":"_dwj2DOqUey2"}},{"cell_type":"markdown","source":["- [Documentación de Statsmodels - Regresión](https://www.statsmodels.org/stable/regression.html) (gratuito, inglés, texto/código)"],"metadata":{"id":"_WsCfAqrVLAi"}},{"cell_type":"markdown","source":["> *Esta página proporciona una visión detallada de las funcionalidades de regresión disponibles en la biblioteca Statsmodels. Ideal para quienes buscan profundizar sus conocimientos en modelos estadísticos y análisis de datos en Python, la documentación presenta explicaciones técnicas, ejemplos de código e información sobre diferentes tipos de regresión, como la regresión lineal y logística.*"],"metadata":{"id":"VVAjj57SVTP6"}},{"cell_type":"markdown","source":["- [Análisis de Regresión - ESALQ](https://www.esalq.usp.br/biblioteca/sites/default/files/Analise_Regress%C3%A3o.pdf) (gratuito, portugués, texto)"],"metadata":{"id":"gaqB_nMUVVmy"}},{"cell_type":"markdown","source":["> *Este documento de ESALQ aborda conceptos y aplicaciones del análisis de regresión, ofreciendo un material rico para estudiantes y profesionales del área de estadística. Con un enfoque didáctico, el texto discute los fundamentos de la regresión, incluyendo modelos lineales y no lineales, además de presentar ejemplos prácticos que ilustran la aplicación de estas técnicas en diferentes contextos.*"],"metadata":{"id":"2Rjz30i5Vafc"}},{"cell_type":"markdown","source":["- [Guía Manga Análisis de Regresión - Google Libros](https://www.google.com.br/books/edition/Guia_Mang%C3%A1_An%C3%A1lise_de_Regress%C3%A3o/QWCHDwAAQBAJ?hl=pt-BR&gbpv=0) (de pago, portugués, texto)"],"metadata":{"id":"nAIsyXbsVcnH"}},{"cell_type":"markdown","source":["> *El \"Guía Manga Análisis de Regresión\" es un enfoque innovador y lúdico para entender el análisis de regresión. Este libro combina ilustraciones al estilo manga con explicaciones técnicas, haciendo que el aprendizaje sea más accesible y divertido. Es una excelente opción para quienes buscan una introducción amigable a los conceptos de regresión, ideal para estudiantes y entusiastas que desean explorar esta área de las matemáticas y la estadística.*"],"metadata":{"id":"alWQI32iVhH8"}},{"cell_type":"markdown","source":[],"metadata":{"id":"J0EVkgtgVmX9"}}]}